{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":17777,"databundleVersionId":869809,"sourceType":"competition"}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-25T15:30:54.043757Z","iopub.execute_input":"2026-01-25T15:30:54.044352Z","iopub.status.idle":"2026-01-25T15:30:54.052782Z","shell.execute_reply.started":"2026-01-25T15:30:54.044321Z","shell.execute_reply":"2026-01-25T15:30:54.052040Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"NLP Disaster Tweet Classification\nKaggle Competition: Natural Language Processing with Disaster Tweets\n\nThis script builds a binary classifier to identify real disaster tweets (1) vs fake/metaphorical (0)","metadata":{}},{"cell_type":"markdown","source":"BERT-Based Disaster Tweet Classification\nF1-Score Target: 0.85-1.00 (State-of-the-art)\n\nThis uses transformer models (DistilBERT) which is how people achieve near-perfect scores.\nRequires: transformers, torch\n\n","metadata":{}},{"cell_type":"code","source":"pip install transformers torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-25T15:30:54.054038Z","iopub.execute_input":"2026-01-25T15:30:54.054329Z","iopub.status.idle":"2026-01-25T15:30:57.321551Z","shell.execute_reply.started":"2026-01-25T15:30:54.054302Z","shell.execute_reply":"2026-01-25T15:30:57.320791Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import DistilBertTokenizer, DistilBertForSequenceClassification\nfrom torch.optim import AdamW  # Import AdamW from torch instead of transformersfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score, classification_report\nfrom tqdm import tqdm\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Check for GPU\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-25T15:45:06.289255Z","iopub.execute_input":"2026-01-25T15:45:06.289900Z","iopub.status.idle":"2026-01-25T15:45:06.295403Z","shell.execute_reply.started":"2026-01-25T15:45:06.289871Z","shell.execute_reply":"2026-01-25T15:45:06.294528Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class TweetDataset(Dataset):\n    \"\"\"Custom dataset for tweets\"\"\"\n    def __init__(self, texts, targets, tokenizer, max_len=128):\n        self.texts = texts\n        self.targets = targets\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n    \n    def __len__(self):\n        return len(self.texts)\n    \n    def __getitem__(self, idx):\n        text = str(self.texts[idx])\n        target = self.targets[idx]\n        \n        encoding = self.tokenizer.encode_plus(\n            text,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            padding='max_length',\n            truncation=True,\n            return_attention_mask=True,\n            return_tensors='pt'\n        )\n        \n        return {\n            'input_ids': encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'targets': torch.tensor(target, dtype=torch.long)\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-25T15:45:09.912299Z","iopub.execute_input":"2026-01-25T15:45:09.912567Z","iopub.status.idle":"2026-01-25T15:45:09.918386Z","shell.execute_reply.started":"2026-01-25T15:45:09.912545Z","shell.execute_reply":"2026-01-25T15:45:09.917746Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_epoch(model, data_loader, optimizer, device):\n    \"\"\"Train for one epoch\"\"\"\n    model.train()\n    losses = []\n    \n    for batch in tqdm(data_loader, desc=\"Training\"):\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        targets = batch['targets'].to(device)\n        \n        optimizer.zero_grad()\n        \n        outputs = model(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            labels=targets\n        )\n        \n        loss = outputs.loss\n        losses.append(loss.item())\n        \n        loss.backward()\n        optimizer.step()\n    \n    return np.mean(losses)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-25T15:45:14.295968Z","iopub.execute_input":"2026-01-25T15:45:14.296673Z","iopub.status.idle":"2026-01-25T15:45:14.301749Z","shell.execute_reply.started":"2026-01-25T15:45:14.296650Z","shell.execute_reply":"2026-01-25T15:45:14.301067Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def eval_model(model, data_loader, device):\n    \"\"\"Evaluate model\"\"\"\n    model.eval()\n    predictions = []\n    real_values = []\n    \n    with torch.no_grad():\n        for batch in tqdm(data_loader, desc=\"Evaluating\"):\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            targets = batch['targets'].to(device)\n            \n            outputs = model(\n                input_ids=input_ids,\n                attention_mask=attention_mask\n            )\n            \n            _, preds = torch.max(outputs.logits, dim=1)\n            \n            predictions.extend(preds.cpu().tolist())\n            real_values.extend(targets.cpu().tolist())\n    \n    return predictions, real_values","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-25T15:45:17.990165Z","iopub.execute_input":"2026-01-25T15:45:17.990443Z","iopub.status.idle":"2026-01-25T15:45:17.995788Z","shell.execute_reply.started":"2026-01-25T15:45:17.990421Z","shell.execute_reply":"2026-01-25T15:45:17.995169Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# DATA LOADING","metadata":{}},{"cell_type":"code","source":"print(\"Loading datasets...\")\ntrain_df = pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')\ntest_df = pd.read_csv('/kaggle/input/nlp-getting-started/test.csv')\n\nprint(f\"Training data shape: {train_df.shape}\")\nprint(f\"Test data shape: {test_df.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-25T15:45:21.841031Z","iopub.execute_input":"2026-01-25T15:45:21.841316Z","iopub.status.idle":"2026-01-25T15:45:21.886026Z","shell.execute_reply.started":"2026-01-25T15:45:21.841295Z","shell.execute_reply":"2026-01-25T15:45:21.885389Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# MINIMAL PREPROCESSING","metadata":{}},{"cell_type":"code","source":"# BERT handles most preprocessing internally, we just need basic cleaning\n\ndef clean_text_bert(text):\n    \"\"\"Minimal cleaning for BERT\"\"\"\n    if pd.isna(text):\n        return \"\"\n    # BERT can handle most text as-is, just basic cleaning\n    text = str(text)\n    return text\n\ntrain_df['text'] = train_df['text'].apply(clean_text_bert)\ntest_df['text'] = test_df['text'].apply(clean_text_bert)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-25T15:45:25.361470Z","iopub.execute_input":"2026-01-25T15:45:25.361762Z","iopub.status.idle":"2026-01-25T15:45:25.371399Z","shell.execute_reply.started":"2026-01-25T15:45:25.361738Z","shell.execute_reply":"2026-01-25T15:45:25.370769Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# SETUP","metadata":{}},{"cell_type":"code","source":"# Initialize tokenizer and model\nMODEL_NAME = 'distilbert-base-uncased'\ntokenizer = DistilBertTokenizer.from_pretrained(MODEL_NAME)\nmodel = DistilBertForSequenceClassification.from_pretrained(\n    MODEL_NAME,\n    num_labels=2\n).to(device)\n\n# Hyperparameters\nBATCH_SIZE = 16\nMAX_LEN = 128\nEPOCHS = 5\nLEARNING_RATE = 2e-5\n\n# Split data\nX_train, X_val, y_train, y_val = train_test_split(\n    train_df['text'].values,\n    train_df['target'].values,\n    test_size=0.15,\n    random_state=42,\n    stratify=train_df['target'].values\n)\n\nprint(f\"\\nTrain size: {len(X_train)}\")\nprint(f\"Validation size: {len(X_val)}\")\n\n# Create datasets\ntrain_dataset = TweetDataset(X_train, y_train, tokenizer, MAX_LEN)\nval_dataset = TweetDataset(X_val, y_val, tokenizer, MAX_LEN)\n\n# Create data loaders\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n\n# Optimizer\noptimizer = AdamW(model.parameters(), lr=LEARNING_RATE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-25T15:45:28.665985Z","iopub.execute_input":"2026-01-25T15:45:28.666721Z","iopub.status.idle":"2026-01-25T15:45:29.334733Z","shell.execute_reply.started":"2026-01-25T15:45:28.666693Z","shell.execute_reply":"2026-01-25T15:45:29.334132Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# TRAINING","metadata":{}},{"cell_type":"code","source":"print(\"\\n\" + \"=\"*50)\nprint(\"Training BERT model...\")\nprint(\"=\"*50)\n\nbest_f1 = 0\n\nfor epoch in range(EPOCHS):\n    print(f\"\\nEpoch {epoch + 1}/{EPOCHS}\")\n    \n    # Train\n    train_loss = train_epoch(model, train_loader, optimizer, device)\n    print(f\"Train loss: {train_loss:.4f}\")\n    \n    # Evaluate\n    predictions, real_values = eval_model(model, val_loader, device)\n    f1 = f1_score(real_values, predictions)\n    \n    print(f\"Validation F1-Score: {f1:.4f}\")\n    print(classification_report(real_values, predictions))\n    \n    if f1 > best_f1:\n        best_f1 = f1\n        torch.save(model.state_dict(), 'best_model.pth')\n        print(f\"✅ Best model saved! F1: {best_f1:.4f}\")\n\n# Load best model\nmodel.load_state_dict(torch.load('best_model.pth'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-25T15:45:34.169178Z","iopub.execute_input":"2026-01-25T15:45:34.169795Z","iopub.status.idle":"2026-01-25T15:49:05.967277Z","shell.execute_reply.started":"2026-01-25T15:45:34.169771Z","shell.execute_reply":"2026-01-25T15:49:05.966647Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# PREDICTION","metadata":{}},{"cell_type":"code","source":"print(\"\\n\" + \"=\"*50)\nprint(\"Generating predictions on test set...\")\nprint(\"=\"*50)\n\n# Create test dataset\ntest_dataset = TweetDataset(\n    test_df['text'].values,\n    np.zeros(len(test_df)),  # Dummy targets\n    tokenizer,\n    MAX_LEN\n)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n\n# Predict\nmodel.eval()\ntest_predictions = []\n\nwith torch.no_grad():\n    for batch in tqdm(test_loader, desc=\"Predicting\"):\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        \n        outputs = model(\n            input_ids=input_ids,\n            attention_mask=attention_mask\n        )\n        \n        _, preds = torch.max(outputs.logits, dim=1)\n        test_predictions.extend(preds.cpu().tolist())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-25T16:07:00.726278Z","iopub.execute_input":"2026-01-25T16:07:00.726888Z","iopub.status.idle":"2026-01-25T16:07:08.367631Z","shell.execute_reply.started":"2026-01-25T16:07:00.726856Z","shell.execute_reply":"2026-01-25T16:07:08.366930Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# SUBMISSION","metadata":{}},{"cell_type":"code","source":"submission = pd.DataFrame({\n    'id': test_df['id'],\n    'target': test_predictions\n})\n\nsubmission.to_csv('submission_bert.csv', index=False)\n\nprint(\"\\n✅ BERT pipeline completed!\")\nprint(f\"Best Validation F1-Score: {best_f1:.4f}\")\nprint(f\"Predicted distribution:\")\nunique, counts = np.unique(test_predictions, return_counts=True)\nfor label, count in zip(unique, counts):\n    print(f\"  Class {label}: {count} ({count/len(test_predictions)*100:.1f}%)\")\nprint(\"\\nSubmission file: submission_bert.csv\")\nprint(\"\\nNote: BERT typically achieves F1-scores of 0.85-1.00 on this competition!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-25T16:07:31.871126Z","iopub.execute_input":"2026-01-25T16:07:31.871415Z","iopub.status.idle":"2026-01-25T16:07:31.882658Z","shell.execute_reply.started":"2026-01-25T16:07:31.871391Z","shell.execute_reply":"2026-01-25T16:07:31.882097Z"}},"outputs":[],"execution_count":null}]}